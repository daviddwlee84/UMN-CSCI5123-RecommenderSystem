# Summary Statistics

> First technique for non-personalized recommendation

## Computing the scores

* What should they mean
  * Popularity (will be challenging)
  * Average rating
  * Probability of you liking
* How to compute
  * Frequency
  * Average
  * More complicated

## Same idea, different formula

* How do we treat score or "good" vs. "awful"

> Now you think about this.  When are you most interested in how often something is good, and when are you interested in how good it is, on average?  Would you rather go on a cruise where 98% of people are pretty happy, or where only 90% are happy, but those 90% are extremely happy?  
>
> This isn’t a new problem -- this problem relates to the economic concept of utility.  It is the same question that may lead some people to decide it is worth buying a lottery ticket every day ($1 a day’s worth of happiness isn’t worth as much as a remote chance of becoming crazy-millionaire happy!) and why others think it is a waste of money.
>
> What do you think?  Do you prefer to gamble for the big win?  Take the safe-but-smaller win?  

* Popularity is an Import Metric
* Average Can be Misleading
  * Can adjust by summing % who like
  * Can adjust by normalizing user ratings
    * normalization addresses different rating scales
  * May want to consider credibility of individual raters (history of ratings)
* More data is better ... to a point
  * Average, Count, Distribution

Missing stuff in non-personalization recommendation

* Who you are
* Your context

## Bias

> * Too many mediocre restaurants with good scores => 22 -> 25
> * Too many excellent restaurants with mediocre scores => 28 -> 26

* Self-selection bias
  * People rate the restaurant they go to
  * You won't go to a store you don't like and give it a negative score
* Increased diversity of raters
  * People have different tastes
  * Average wash together

## Take-away

* Non-personalization popularity statistics or average can be effective in the right application
  * Need to understand relationship between average and user need; correct average
* In many cases it can be best to show count, average, and distribution together
* For ranking, one alternative to average is the percentage who score above a threshold (or below)
* Personalization would address many limitations

> ![poll](Poll.png)
>
> Now that you’ve seen what others said, here’s our thinking …
>
> We wouldn’t personalize to the customer here, because just because I enjoy mustard doesn’t mean I want it on ice cream.  I’d probably choose to go with “most common with a particular food,” but either of the filter lists could be used as a way to mix a “let’s not embarrass ourselves” into another form of recommender.  As to whether to do it automatically or manually, that depends on what type of embarrassment you’re worried about.  An automatic list is easier, but it might invite occasional attacks (from the ketchup sundae brigade) and might not recognize cultural faux pas (such as avoiding meat sauce on ice cream for customers who keep Kosher).

---

1. What predictions to show
2. How to rank

* Computing and displaying predictions
* How to rank items with sparse or time-shifting data
* Design space for prediction and recommendation

## Example

### Reddit

* Social news aggregator

## Displaying Aggregate Preferences (predict)

Goal of Display: to help users decide to buy/read/view the item

### Simple Display Approaches

* Average rating /upvote proportion
  * of people who vote, do they like it?
  * doesn't show popularity
* Net upvotes / # of likes
  * shows popularity
  * no controversy
    * 0 vs. 5
    * 4995 vs. 5000
* % >= 4 stars (positive)
* Full distribution
  * complicated

## Ranking Items (recommend)

> What do you put at the top

Domain or business considerations

* Item is old
* Item is "unfavored"

### Ranking Considerations

* Confidence
* Risk tolerance
  * high-risk, high-reward
  * conservative recommendation
* Domain and business considerations
  * age
  * system goals

#### Damped means

* Problem: low confidence with few ratings
* Solution: assume that, without evidence, everything is average

k => strength required (for evidence to overcome the global mean)

$$
{\sum_u{r_{ui} + k \mu} \over n \times k}
$$

#### Confidence Intervals

> Wilson confidence interval

* From the reading: lower bound of statistical confidence interval (95%)
* Choice of bound affects risk/confidence
* ...

> e.g. Reddit comments

### Domain Consideration: Time

* Reddit: old stories aren't interesting
* eBay: items have short lifetimes

#### Scoring news stories

**Hacker News**

* Net upvotes, polynomially decayed by age
* Old items scored mostly by vote
* Multiplied by item penalty terms
  * incorporate community goals into score

> The purpose of the Polynomial decay applied to the Net vote count: To decrease the impact of later votes on highly-voted posts, allowing new but interesting topics to overcome older popular topics.

$\alpha = 0.8, \gamma = 1.8$

$$
\frac{(U - D - 1)^\alpha}{(t_{now} - t_{post})^\gamma} \cdot P
$$

* $P$ is penalty
* U: up vote
* D: down vote

$age = t_{now} - t_{post}$

net vote = $U - D - 1$

**Reddit News**

> 45000 is a site specific constant

$$
\log_{10} \max (1, |U - D|) + {sign(U-D) t_{post} \over 45000}
$$

### Ranking Wrap-Up

* There are some theoretically grounded approaches
  * confidence interval
  * damping
* Many sites use ad-hoc methods
* Many formulas have constants, will be highly service-dependent
* Can manipulate for "good" or "evil"
* Build based on domain properties, goals

## Predict with sophisticated score

* Theoretically a fine thing to do
* Be careful with transparency/scrutability
  * If you save "average rating" for damped mean, and show ratings, users may be confused
  * Most important case (low ratings) also easiest to hand-verify

## Conclusion

* Sparsity, inconsistency, temporal concerns make data messy
* Simple scoring doesn't necessarily match the domain or business
  * Decay
  * Time
  * Penalties
  * Damping

> Q:Think of an example of a business rule that the operators of a question & answer site might want to impose to adjust the scores by which questions are ranked.
>
> A: More complete answer or question that makes sense.
> Some "current event" topic question, should be treated like Reddit News or something. (e.g. A specific question for a programming language but outdated.)

Some potential examples:

* Demote short questions
* Demote questions containing only a link
* Promote questions that are well-tagged
* Promote unanswered questions
